# Data Structures

## 1. Introduction
1. **Data Types** - Explanation of different types of data in programming.
2. **Reference Type** - Understanding objects stored by reference.
3. **Value Type** - How value types store data directly in memory.
4. **Storing Data in Computer Memory** - Overview of how data is managed in memory.

## 2. Array
1. **Introduction and Basic Concepts** - Fundamentals of arrays and their importance.
2. **Static Array** - Arrays with fixed size and their characteristics.
3. **Dynamic Array** - Resizable arrays and how they manage memory.
4. **Array Operations** - Common operations like insertion, deletion, searching, and sorting.
5. **Application Areas of Arrays** - Practical applications of arrays in real-world scenarios.


## 3. Singly Linked List  
1. **Introduction and Basic Concepts** - Understanding singly linked lists and their significance in data structures.  
2. **Node Structure** - Explanation of the `SinglyLinkedListNode` class, which stores data and a pointer to the next node.  
3. **Singly Linked List Operations**  
   - **Insertion** - Adding elements at the beginning, end, or a specific position.  
   - **Deletion** - Removing the first, last, or a specific node.  
   - **Traversal** - Iterating through the linked list using an enumerator.  
   - **Searching** - Finding a specific node in the list.  
4. **Memory Management in Singly Linked Lists** - How nodes are dynamically allocated and deallocated.  
5. **Application Areas of Singly Linked Lists** - Practical uses in software development, such as queue implementations, undo features, and memory-efficient data storage.  

## 4. Stack  
1. **Introduction and Basic Concepts**  
   - Understanding the LIFO (Last-In, First-Out) principle that defines a stack.  
   - Real-world analogies like a stack of plates or books.  
   - Importance in algorithm design and memory management.

2. **Stack Structure**  
   - Explanation of the internal structure of a stack.  
   - Common implementations using arrays and linked lists.  
   - Core components: `push`, `pop`, `peek`, and `isEmpty` operations.

3. **Stack Operations**  
   - **Push** - Adding an element to the top of the stack.  
   - **Pop** - Removing the top element from the stack.  
   - **Peek (or Top)** - Viewing the top element without removing it.  
   - **IsEmpty** - Checking if the stack is empty.  
   - **Size** - Getting the number of elements in the stack.

4. **Memory Management in Stack**  
   - Stack memory allocation and deallocation.  
   - Call stack usage during function execution.  
   - Stack overflow issues and limitations in memory-constrained environments.

5. **Application Areas of Stacks**  
   - Function call management in programming languages (call stack).  
   - Expression evaluation and syntax parsing.  
   - Backtracking algorithms (e.g., maze solving, undo operations).  
   - Depth-First Search (DFS) in graph traversal.  

## 5. Queue

### 1. Introduction and Basic Concepts
- Understanding the FIFO (First-In, First-Out) principle that defines a queue.
- Real-world analogies such as queues in supermarkets or print job scheduling.
- Importance in algorithm design, scheduling, and resource management.

### 2. Queue Structure
- Explanation of the internal structure of a queue.
- Common implementations using arrays, linked lists, and circular buffers.
- Core components: `enqueue`, `dequeue`, `peek`, and `isEmpty` operations.

### 3. Queue Operations
- **Enqueue** - Adding an element to the rear (end) of the queue.
- **Dequeue** - Removing an element from the front of the queue.
- **Peek (or Front)** - Viewing the front element without removing it.
- **IsEmpty** - Checking if the queue is empty.
- **Size** - Getting the number of elements currently stored in the queue.

### 4. Memory Management in Queue
- Dynamic vs. static memory allocation for queues.
- Circular queue implementations to optimize space utilization.
- Buffer overflow/underflow issues and preventive mechanisms.

### 5. Application Areas of Queues
- Scheduling processes in operating systems (CPU scheduling, IO queues).
- Managing print jobs in printers (print spooling).
- Breadth-First Search (BFS) in graph traversal.
- Simulation systems (e.g., customer service systems, traffic flow models).
- Message queues in distributed systems and asynchronous programming.

## 6. Sorting Algorithms

### 1. Introduction to Sorting Algorithms
- Importance of sorting in computer science.
- Comparison of different sorting techniques based on time complexity, space complexity, and stability.

### 2. Bubble Sort
- Simple comparison-based algorithm.
- Repeatedly swaps adjacent elements if they are in the wrong order.
- **Best case**: O(n), **Worst case**: O(n¬≤), **Space**: O(1).

### 3. Insertion Sort
- Builds the final sorted array one element at a time.
- Good for small or nearly sorted datasets.
- **Best case**: O(n), **Worst case**: O(n¬≤), **Space**: O(1).

### 4. Selection Sort
- Repeatedly finds the minimum element and moves it to the sorted portion.
- Always O(n¬≤) time complexity.
- Not stable but simple to implement.

### 5. Merge Sort
- Divide-and-conquer algorithm that divides the list into halves, sorts them, and merges.
- **Time complexity**: O(n log n) in all cases.
- **Space complexity**: O(n).

### 6. Quick Sort
- Divide-and-conquer algorithm that picks a pivot and partitions the array.
- **Best/Average case**: O(n log n), **Worst case**: O(n¬≤) (can be improved with randomized pivot).
- **Space**: O(log n) due to recursion stack.

## 7. Algorithm Analysis Techniques

### 1. Time Complexity
- Time complexity describes how the runtime of an algorithm increases with the size of the input.
- Helps evaluate the efficiency of algorithms.
- Common complexities:
  - **O(1)** ‚Äì Constant time
  - **O(log n)** ‚Äì Logarithmic time
  - **O(n)** ‚Äì Linear time
  - **O(n log n)** ‚Äì Linearithmic time
  - **O(n¬≤)** ‚Äì Quadratic time
  - **O(2‚Åø), O(n!)** ‚Äì Exponential time

### 2. Asymptotic Notation
- Used to describe the upper, lower, or tight bound behavior of an algorithm:
  - **Big O (O)** ‚Äì Worst-case upper bound  
    Example: O(n¬≤) means the runtime grows at most as n¬≤.
  - **Big Omega (Œ©)** ‚Äì Best-case lower bound  
    Example: Œ©(n) means the algorithm takes at least linear time.
  - **Big Theta (Œò)** ‚Äì Tight bound (both upper and lower)  
    Example: Œò(n log n) means the runtime grows exactly at that rate.

### 3. Substitution Method
- A method to solve recurrence relations by guessing the form of the solution and proving it using mathematical induction.
- **Example:**
  - T(n) = 2T(n/2) + n  
  - Guess: T(n) = O(n log n)  
  - Prove the guess using induction.

### 4. Iteration Method
- Solves recurrence relations by expanding them step by step until a pattern is observed.
- **Example:**
  - T(n) = T(n/2) + n  
  - T(n/2) = T(n/4) + n/2  
  - ‚Ä¶
  - Total = n + n/2 + n/4 + ‚Ä¶ = O(n)

### 5. Master Theorem
- Provides a direct way to analyze the time complexity of divide-and-conquer algorithms.
- Applies to recurrences of the form:  
  **T(n) = aT(n/b) + f(n)**  
- **Cases:**
  1. If f(n) = O(n^log_b(a - Œµ)) ‚Üí T(n) = Œò(n^log_b(a))
  2. If f(n) = Œò(n^log_b(a)) ‚Üí T(n) = Œò(n^log_b(a) * log n)
  3. If f(n) = Œ©(n^log_b(a + Œµ)) and regularity condition holds ‚Üí T(n) = Œò(f(n))
- **Example:**
  - Merge Sort: T(n) = 2T(n/2) + n ‚Üí Case 2 ‚Üí Œò(n log n)


  ## 8. Tree, Binary Tree, Binary Search Tree

### 1. Tree
- A **tree** is a hierarchical data structure consisting of nodes.
- The top node is called the **root**; nodes without children are called **leaves**.
- Each node (except the root) has exactly one parent.
- Trees are used in many applications like file systems, databases, and parsing expressions.
- **Terminology:**
  - **Parent, Child, Sibling**
  - **Subtree**: A tree formed by a node and its descendants.
  - **Depth**: Number of edges from root to node.
  - **Height**: Number of edges on the longest path from node to a leaf.

### 2. Binary Tree
- A **binary tree** is a tree where each node has at most two children: **left** and **right**.
- Types of binary trees:
  - **Full Binary Tree**: Every node has 0 or 2 children.
  - **Complete Binary Tree**: All levels are filled except possibly the last, which is filled from left to right.
  - **Perfect Binary Tree**: All internal nodes have two children and all leaves are at the same level.
- Common traversals:
  - **Inorder (Left, Root, Right)**
  - **Preorder (Root, Left, Right)**
  - **Postorder (Left, Right, Root)**
  - **Level-order (Breadth-First Search)**

### 3. Binary Search Tree (BST)
- A **Binary Search Tree** is a binary tree with the property:
  - For any node `n`:  
    - All values in the left subtree < `n.value`  
    - All values in the right subtree > `n.value`
- Operations:
  - **Search**: O(h) time complexity (h = tree height)
  - **Insert**: O(h)
  - **Delete**: O(h)
- Best case: **Balanced BST** ‚Üí O(log n)  
- Worst case: **Unbalanced BST** (like a linked list) ‚Üí O(n)
- BSTs are used in:
  - Dynamic sets
  - Searching and sorting
  - Dictionary implementations


## 9. Heap, Binary Heap, Min Heap, Max Heap

### 1. Heap
- A **heap** is a special **tree-based** data structure that satisfies the **heap property**.
- It is usually implemented as a **complete binary tree**.
- **Heap property**:
  - In a **Max Heap**: Parent node ‚â• Children
  - In a **Min Heap**: Parent node ‚â§ Children
- Common uses:
  - **Priority queues**
  - **Heap Sort**
  - **Task scheduling**

### 2. Binary Heap
- A **binary heap** is a **complete binary tree** that satisfies the **heap property**.
- Typically implemented using an **array**:
  - For a node at index `i`:
    - Left child ‚Üí `2i + 1`
    - Right child ‚Üí `2i + 2`
    - Parent ‚Üí `(i - 1) / 2`

### 3. Min Heap
- A **Min Heap** is a binary heap where:
  - The **root** contains the **smallest** element.
  - Each parent node ‚â§ its children.
- Operations:
  - **Insert**: O(log n)
  - **Extract-Min**: O(log n)
  - **Peek-Min**: O(1)
- Applications:
  - **Dijkstra‚Äôs algorithm**
  - **Minimum spanning tree (Prim‚Äôs algorithm)**
  - **Event simulation**

### 4. Max Heap
- A **Max Heap** is a binary heap where:
  - The **root** contains the **largest** element.
  - Each parent node ‚â• its children.
- Operations:
  - **Insert**: O(log n)
  - **Extract-Max**: O(log n)
  - **Peek-Max**: O(1)
- Applications:
  - **Heap Sort**
  - **Priority queues**
  - **Finding the k largest elements**

## 9. Disjoint Set (Union-Find)

### 1. Disjoint Set
- A **Disjoint Set** (also known as **Union-Find**) is a data structure that keeps track of a partition of elements into **disjoint (non-overlapping) subsets**.
- It provides efficient support for the following operations:
  - **MakeSet(x)**: Creates a set containing a single element `x`.
  - **FindSet(x)**: Returns the representative (or "leader") of the set that contains `x`.
  - **Union(x, y)**: Merges the sets containing elements `x` and `y`.

### 2. Disjoint Set Representation
- Internally, each set is represented as a **tree**, with each node pointing to its **parent**.
- The **representative** of a set is the **root** of its tree.
- Optimizations:
  - **Path Compression**: Flattens the structure of the tree whenever `FindSet` is called, speeding up future queries.
  - **Union by Rank / Size**: Always attach the smaller tree to the root of the larger one to keep trees shallow.

### 3. Operations and Complexity

| Operation      | Description                                | Time Complexity |
|----------------|--------------------------------------------|-----------------|
| `MakeSet(x)`   | Initializes a new set with element `x`     | O(1)            |
| `FindSet(x)`   | Returns the root of the set containing `x` | O(Œ±(n))         |
| `Union(x, y)`  | Merges the sets containing `x` and `y`     | O(Œ±(n))         |

> üîπ Here, `Œ±(n)` is the **inverse Ackermann function**, which grows extremely slowly. For all practical values of `n`, it is ‚â§ 5.

### 4. Applications
- **Kruskal‚Äôs algorithm** for finding the **Minimum Spanning Tree**
- **Connected component detection** in graphs
- **Image segmentation** in computer vision
- **Network connectivity** checking
- **Cycle detection** in undirected graphs
